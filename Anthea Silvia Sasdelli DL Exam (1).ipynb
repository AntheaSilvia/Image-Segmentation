{"cells":[{"cell_type":"markdown","metadata":{"id":"zPGUUzzy1JyX"},"source":["#Exam of Anthea Silvia Sasdelli\n","September session 2023\n","\n","## Satellite images segmentation\n","\n","The task consists of creating a neural model able to perform semantic segmentation on satellite images into six (seven with the no information) different classes.\n","\n","In this project, the input-target pair is composed by a $1000 \\times 1000$ RGB image as visualized above, together with a $1000 \\times 1000$ mask, that classifies each pixel by assigning to it a real number."]},{"cell_type":"markdown","source":["##Import the libraries"],"metadata":{"id":"cLekqD71S8pL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jj48L2641B-u"},"outputs":[],"source":["# Utilities\n","import os\n","from glob import glob\n","from IPython.utils import io\n","\n","# Algebra\n","import numpy as np\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import cv2\n","\n","# Neural Networks\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from keras.callbacks import EarlyStopping\n","from keras import backend as K"]},{"cell_type":"markdown","metadata":{"id":"fE6tq__W2VG_"},"source":["The data is downloaded by a local file due to problems with the dataset link."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfoPUGEM2UkK"},"outputs":[],"source":["with io.capture_output() as captured:\n","  !gdown 1jOljqtxkSqeI4s04RanUlIATDKBY0wUR\n","  !unzip ign_dataset.zip\n","  !rm ign_dataset.zip"]},{"cell_type":"markdown","source":["##Preprocessing of the data\n","The dataset contained two folders:\n","\n","\n","*   Images: 1000Ã—1000  RGB image\n","*   Annotation: 1000x1000 masks\n","\n","Each one was divided in training and validation, which was used as test set."],"metadata":{"id":"3rwQBgmsTc3q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qEMnF_f3NTv"},"outputs":[],"source":["X_path = './ign/images/'\n","Y_path = './ign/annotations/'\n","\n","#Lists of the names of the files\n","\n","image_train = sorted(os.listdir(os.path.join(X_path, 'training')))\n","image_test = sorted(os.listdir(os.path.join(X_path, 'validation')))\n","mask_train = sorted(os.listdir(os.path.join(Y_path, 'training')))\n","mask_test = sorted(os.listdir(os.path.join(Y_path, 'validation')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sGTKx1kHW-9K"},"outputs":[],"source":["def load_dataset(image_root_path, mask_root_path, image_file_names, mask_file_names):\n","    num_samples = len(image_file_names)\n","    image_size = (256, 256)\n","    num_channels = 3\n","\n","    # Initialize arrays to store images and masks\n","    images = np.zeros((num_samples, *image_size, num_channels), dtype=np.uint8)\n","    masks = np.zeros((num_samples, *image_size), dtype=np.float32)\n","\n","    for i, (image_name, mask_name) in enumerate(zip(image_file_names, mask_file_names)):\n","        # Load and resize the RGB image\n","        image_path = os.path.join(image_root_path, image_name)\n","        img = Image.open(image_path).convert('RGB')\n","        img = img.resize(image_size, Image.NEAREST)\n","        images[i] = np.array(img)\n","\n","        # Load and resize the mask\n","        mask_path = os.path.join(mask_root_path, mask_name)\n","        mask = Image.open(mask_path).convert('L')\n","        mask = mask.resize(image_size, Image.NEAREST)\n","        masks[i] = np.array(mask)\n","\n","    return images, masks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0OriT7uBW7j"},"outputs":[],"source":["x_train, y_train = load_dataset('./ign/images/training/', './ign/annotations/training/', image_train, mask_train)\n","x_test, y_test = load_dataset('./ign/images/validation/', './ign/annotations/validation/', image_test, mask_test)"]},{"cell_type":"markdown","source":["Since the masks dataset had an unusual format, i decided to encode both train and validation with a one hot encoding in order to have the shape  $batch \\times height \\times width \\times num. class$"],"metadata":{"id":"JsOhewg5VNmO"}},{"cell_type":"code","source":["def batch_to_one_hot(batch, num_classes):\n","    \"\"\"\n","    Convert a batch of integer class label masks to one-hot encoding.\n","\n","    Args:\n","        batch (numpy.ndarray): Batch of integer class label masks with shape (batch_size, size, size).\n","        num_classes (int): The number of classes in the dataset.\n","\n","    Returns:\n","        numpy.ndarray: One-hot encoding of the input batch with shape (batch_size, size, size, num_classes).\n","    \"\"\"\n","    # Create an empty one-hot encoding array\n","    one_hot_encoding = np.zeros((batch.shape[0], batch.shape[1], batch.shape[2], num_classes), dtype=np.float32)\n","\n","    # Iterate through each class label and set the corresponding channel to 1\n","    for class_index in range(num_classes):\n","        one_hot_encoding[:, :, :, class_index] = (batch == class_index).astype(np.float32)\n","\n","    return one_hot_encoding\n","\n","y_train = batch_to_one_hot(y_train, 7)\n"],"metadata":{"id":"c1AFUuuwKHdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test = batch_to_one_hot(y_test, 7)"],"metadata":{"id":"dJJVnRcSpyrW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["So now they have this shape:"],"metadata":{"id":"Q4zyyAeIW16M"}},{"cell_type":"code","source":["y_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzr8NqiOW5Dz","executionInfo":{"status":"ok","timestamp":1694413362434,"user_tz":-120,"elapsed":12,"user":{"displayName":"Anthea Silvia Sasdelli","userId":"09097632666158276833"}},"outputId":"56811775-f56f-415d-fff2-29c46322a037"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(600, 256, 256, 7)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"G6lLIKLLHBxW"},"source":["##Visualization\n","Here there is an example of the same image with all the different 7 channels of the mask, showing the pixels that are in that class."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1wG-TNleP_2a6NhxUcy1n4xuQMgOazsox"},"executionInfo":{"elapsed":6786,"status":"ok","timestamp":1694414053993,"user":{"displayName":"Anthea Silvia Sasdelli","userId":"09097632666158276833"},"user_tz":-120},"id":"Si9qkr9ZHEIU","outputId":"6328eb71-d723-40ca-f2f1-b2faae594bcd"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["def show(x, y, title):\n","    plt.figure(figsize=(10, 7))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(x)\n","    if title:\n","        plt.title(title[0])\n","\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(y)\n","    if title:\n","        plt.title(title[1])\n","\n","    plt.show()\n","\n","for i in range(y_train.shape[3]):\n","  show(x_train[150], y_train[150][...,i], ('This is the image', 'This is its relative mask of the channel '+str(i)))"]},{"cell_type":"markdown","metadata":{"id":"wAzYoQJfK-kK"},"source":["## U-Net\n","The U-Net architecture is chosen for multiclass semantic segmentation due to its specialized design, incorporating encoder and decoder networks with skip connections for precise localization. It effectively captures semantic information, distinguishing between classes.\n","\n","In the specific it is composed by:\n","\n","*   **Input layer**\n","*   **Contractive path**, where the spatial information is reduced while the feature information is increased\n","*   **The bottom layer**\n","*   **Expansive path**, where the data is rexpanded and the layers are concatenated with the corresponded layer in the contractive path\n","*   **The output layer**\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bJVQhZgLFrU"},"outputs":[],"source":["FILTER = 4\n","\n","IMAGE_WIDTH = 256\n","IMAGE_HEIGHT = 256\n","IMAGE_CHANNELS = 3"]},{"cell_type":"code","source":["'''Input layer'''\n","\n","inputs = tf.keras.layers.Input((IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))"],"metadata":{"id":"RWXBY34trver"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' Contractive path '''\n","\n","### Layer 1\n","c1 = tf.keras.layers.Conv2D(FILTER, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(inputs)\n","c1 = tf.keras.layers.Dropout(0.1)(c1)\n","c1 = tf.keras.layers.Conv2D(FILTER, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c1)\n","p1 = tf.keras.layers.MaxPool2D((2, 2))(c1)\n","\n","### Layer 2\n","c2 = tf.keras.layers.Conv2D(FILTER*2, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(p1)\n","c2 = tf.keras.layers.Dropout(0.1)(c2)\n","c2 = tf.keras.layers.Conv2D(FILTER*2, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c2)\n","p2 = tf.keras.layers.MaxPool2D((2, 2))(c2)\n","\n","### Layer 3\n","c3 = tf.keras.layers.Conv2D(FILTER*4, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(p2)\n","c3 = tf.keras.layers.Dropout(0.2)(c3)\n","c3 = tf.keras.layers.Conv2D(FILTER*4, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c3)\n","p3 = tf.keras.layers.MaxPool2D((2, 2))(c3)\n","\n","### Layer 4\n","c4 = tf.keras.layers.Conv2D(FILTER*8, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(p3)\n","c4 = tf.keras.layers.Dropout(0.2)(c4)\n","c4 = tf.keras.layers.Conv2D(FILTER*8, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c4)\n","p4 = tf.keras.layers.MaxPool2D((2, 2))(c4)\n","\n","### Layer 5, bottom layer\n","c5 = tf.keras.layers.Conv2D(FILTER*16, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(p4)\n","c5 = tf.keras.layers.Dropout(0.3)(c5)\n","c5 = tf.keras.layers.Conv2D(FILTER*16, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c5)\n","\n"],"metadata":{"id":"zAk1P75WsGKF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''Expansive path'''\n","\n","### Layer 6\n","u6 = tf.keras.layers.Conv2DTranspose(FILTER*8, (2, 2),\n","                                     strides = (2, 2),\n","                                     padding = 'same')(c5)\n","\n","u6 = tf.keras.layers.concatenate([u6, c4])\n","\n","c6 = tf.keras.layers.Conv2D(FILTER*8, (3, 3),\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(u6)\n","\n","c6 = tf.keras.layers.Dropout(0.2)(c6)\n","\n","c6 = tf.keras.layers.Conv2D(FILTER*8, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c6)\n","\n","### Layer 7\n","u7 = tf.keras.layers.Conv2DTranspose(FILTER*4, (2, 2),\n","                                     strides = (2, 2),\n","                                     padding = 'same')(c6)\n","\n","c7 = tf.keras.layers.concatenate([u7, c3])\n","\n","c7 = tf.keras.layers.Conv2D(FILTER*4, (3, 3),\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c7)\n","\n","c7 = tf.keras.layers.Dropout(0.2)(c7)\n","\n","c7 = tf.keras.layers.Conv2D(FILTER*4, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c7)\n","\n","### Layer 8\n","u8 = tf.keras.layers.Conv2DTranspose(FILTER*2, (2, 2),\n","                                     strides = (2, 2),\n","                                     padding = 'same')(c7)\n","\n","u8 = tf.keras.layers.concatenate([u8, c2])\n","\n","c8 = tf.keras.layers.Conv2D(FILTER*2, (3, 3),\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(u8)\n","\n","c8 = tf.keras.layers.Dropout(0.1)(c8)\n","\n","c8 = tf.keras.layers.Conv2D(FILTER*2, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c8)\n","\n","### Layer 9\n","u9 = tf.keras.layers.Conv2DTranspose(FILTER, (2, 2),\n","                                     strides = (2, 2),\n","                                     padding = 'same')(c8)\n","\n","u9 = tf.keras.layers.concatenate([u9, c1])\n","\n","c9 = tf.keras.layers.Conv2D(FILTER, (3, 3),\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(u9)\n","\n","c9 = tf.keras.layers.Dropout(0.1)(c9)\n","\n","c9 = tf.keras.layers.Conv2D(FILTER, (3, 3),\n","                            activation = 'selu',\n","                            kernel_initializer = 'he_normal',\n","                            padding = 'same')(c9)"],"metadata":{"id":"p0v8Bx8Lt_wC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''Output layer'''\n","outputs = tf.keras.layers.Conv2D(7, (1, 1), activation = 'softmax')(c9)"],"metadata":{"id":"tfY6gAdswVSK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' Model building '''\n","model_1 = tf.keras.Model(inputs = [inputs], outputs = [outputs])\n","model_1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XCdhHx_lwf30","executionInfo":{"status":"ok","timestamp":1694420390775,"user_tz":-120,"elapsed":909,"user":{"displayName":"Anthea Silvia Sasdelli","userId":"09097632666158276833"}},"outputId":"84cd968d-e639-4fb4-dffe-ffcc7350c2c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_3 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n","                                                                                                  \n"," conv2d_38 (Conv2D)          (None, 256, 256, 4)          112       ['input_3[0][0]']             \n","                                                                                                  \n"," dropout_18 (Dropout)        (None, 256, 256, 4)          0         ['conv2d_38[0][0]']           \n","                                                                                                  \n"," conv2d_39 (Conv2D)          (None, 256, 256, 4)          148       ['dropout_18[0][0]']          \n","                                                                                                  \n"," max_pooling2d_8 (MaxPoolin  (None, 128, 128, 4)          0         ['conv2d_39[0][0]']           \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_40 (Conv2D)          (None, 128, 128, 8)          296       ['max_pooling2d_8[0][0]']     \n","                                                                                                  \n"," dropout_19 (Dropout)        (None, 128, 128, 8)          0         ['conv2d_40[0][0]']           \n","                                                                                                  \n"," conv2d_41 (Conv2D)          (None, 128, 128, 8)          584       ['dropout_19[0][0]']          \n","                                                                                                  \n"," max_pooling2d_9 (MaxPoolin  (None, 64, 64, 8)            0         ['conv2d_41[0][0]']           \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_42 (Conv2D)          (None, 64, 64, 16)           1168      ['max_pooling2d_9[0][0]']     \n","                                                                                                  \n"," dropout_20 (Dropout)        (None, 64, 64, 16)           0         ['conv2d_42[0][0]']           \n","                                                                                                  \n"," conv2d_43 (Conv2D)          (None, 64, 64, 16)           2320      ['dropout_20[0][0]']          \n","                                                                                                  \n"," max_pooling2d_10 (MaxPooli  (None, 32, 32, 16)           0         ['conv2d_43[0][0]']           \n"," ng2D)                                                                                            \n","                                                                                                  \n"," conv2d_44 (Conv2D)          (None, 32, 32, 32)           4640      ['max_pooling2d_10[0][0]']    \n","                                                                                                  \n"," dropout_21 (Dropout)        (None, 32, 32, 32)           0         ['conv2d_44[0][0]']           \n","                                                                                                  \n"," conv2d_45 (Conv2D)          (None, 32, 32, 32)           9248      ['dropout_21[0][0]']          \n","                                                                                                  \n"," max_pooling2d_11 (MaxPooli  (None, 16, 16, 32)           0         ['conv2d_45[0][0]']           \n"," ng2D)                                                                                            \n","                                                                                                  \n"," conv2d_46 (Conv2D)          (None, 16, 16, 64)           18496     ['max_pooling2d_11[0][0]']    \n","                                                                                                  \n"," dropout_22 (Dropout)        (None, 16, 16, 64)           0         ['conv2d_46[0][0]']           \n","                                                                                                  \n"," conv2d_47 (Conv2D)          (None, 16, 16, 64)           36928     ['dropout_22[0][0]']          \n","                                                                                                  \n"," conv2d_transpose_8 (Conv2D  (None, 32, 32, 32)           8224      ['conv2d_47[0][0]']           \n"," Transpose)                                                                                       \n","                                                                                                  \n"," concatenate_8 (Concatenate  (None, 32, 32, 64)           0         ['conv2d_transpose_8[0][0]',  \n"," )                                                                   'conv2d_45[0][0]']           \n","                                                                                                  \n"," conv2d_48 (Conv2D)          (None, 32, 32, 32)           18464     ['concatenate_8[0][0]']       \n","                                                                                                  \n"," dropout_23 (Dropout)        (None, 32, 32, 32)           0         ['conv2d_48[0][0]']           \n","                                                                                                  \n"," conv2d_49 (Conv2D)          (None, 32, 32, 32)           9248      ['dropout_23[0][0]']          \n","                                                                                                  \n"," conv2d_transpose_9 (Conv2D  (None, 64, 64, 16)           2064      ['conv2d_49[0][0]']           \n"," Transpose)                                                                                       \n","                                                                                                  \n"," concatenate_9 (Concatenate  (None, 64, 64, 32)           0         ['conv2d_transpose_9[0][0]',  \n"," )                                                                   'conv2d_43[0][0]']           \n","                                                                                                  \n"," conv2d_50 (Conv2D)          (None, 64, 64, 16)           4624      ['concatenate_9[0][0]']       \n","                                                                                                  \n"," dropout_24 (Dropout)        (None, 64, 64, 16)           0         ['conv2d_50[0][0]']           \n","                                                                                                  \n"," conv2d_51 (Conv2D)          (None, 64, 64, 16)           2320      ['dropout_24[0][0]']          \n","                                                                                                  \n"," conv2d_transpose_10 (Conv2  (None, 128, 128, 8)          520       ['conv2d_51[0][0]']           \n"," DTranspose)                                                                                      \n","                                                                                                  \n"," concatenate_10 (Concatenat  (None, 128, 128, 16)         0         ['conv2d_transpose_10[0][0]', \n"," e)                                                                  'conv2d_41[0][0]']           \n","                                                                                                  \n"," conv2d_52 (Conv2D)          (None, 128, 128, 8)          1160      ['concatenate_10[0][0]']      \n","                                                                                                  \n"," dropout_25 (Dropout)        (None, 128, 128, 8)          0         ['conv2d_52[0][0]']           \n","                                                                                                  \n"," conv2d_53 (Conv2D)          (None, 128, 128, 8)          584       ['dropout_25[0][0]']          \n","                                                                                                  \n"," conv2d_transpose_11 (Conv2  (None, 256, 256, 4)          132       ['conv2d_53[0][0]']           \n"," DTranspose)                                                                                      \n","                                                                                                  \n"," concatenate_11 (Concatenat  (None, 256, 256, 8)          0         ['conv2d_transpose_11[0][0]', \n"," e)                                                                  'conv2d_39[0][0]']           \n","                                                                                                  \n"," conv2d_54 (Conv2D)          (None, 256, 256, 4)          292       ['concatenate_11[0][0]']      \n","                                                                                                  \n"," dropout_26 (Dropout)        (None, 256, 256, 4)          0         ['conv2d_54[0][0]']           \n","                                                                                                  \n"," conv2d_55 (Conv2D)          (None, 256, 256, 4)          148       ['dropout_26[0][0]']          \n","                                                                                                  \n"," conv2d_56 (Conv2D)          (None, 256, 256, 7)          35        ['conv2d_55[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 121755 (475.61 KB)\n","Trainable params: 121755 (475.61 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["In order to perform better the metrics of the Dice Coefficient later in the model evaluation, it has been chosen to use a customized Loss `dice_coef_loss` and Metrics `dice_coef_multilabel` for the training of the U-Net."],"metadata":{"id":"-egYm3eyFlT7"}},{"cell_type":"code","source":["'''Customized loss for the model'''\n","\n","def dice_coef_loss(y_true, y_pred):\n","    smooth = 0.001\n","\n","    # Flatten the one-hot encoded tensors\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    dice_loss = 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","    return dice_loss"],"metadata":{"id":"7sgbQtHqGId7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''Customized metrics'''\n","\n","def dice_coefficient(y_true, y_pred):\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n","    return (2.0 * intersection) / (union + intersection)\n","\n","def dice_coef_multilabel(y_true, y_pred):\n","    dice=0\n","    for index in range(7):\n","        dice += dice_coefficient(y_true[:,:,:,index], y_pred[:,:,:,index])\n","    return dice/7\n","\n"],"metadata":{"id":"YnRWEjL97FFj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Early Stopping was chosen in order to prevent overfitting by monitoring a specific metric, in this case the Accuracy and stopping training if the metric stops improving."],"metadata":{"id":"Ut92FPl0GZxV"}},{"cell_type":"code","source":["def setup_early_stopping(patience, monitor, mode):\n","    \"\"\"\n","    Set up early stopping to prevent overfitting during training.\n","\n","    Parameters:\n","    - patience: Number of epochs with no improvement after which training will be stopped.\n","    - monitor: The quantity to be monitored (e.g., 'val_loss' for validation loss).\n","    - mode: One of {'auto', 'min', 'max'}. In 'min' mode, training will stop when the monitored quantity has stopped decreasing. In 'max' mode, it will stop when the monitored quantity has stopped increasing.\n","\n","    Returns:\n","    - EarlyStopping callback object to be used during model training.\n","    \"\"\"\n","    early_stopping = EarlyStopping(monitor=monitor, patience=patience, mode=mode)\n","    return early_stopping\n"],"metadata":{"id":"O_1t4yldLJkB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stopping = setup_early_stopping(patience=5, monitor='accuracy', mode='auto')"],"metadata":{"id":"29MGj8ZYLV60"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now the model is compiled and trained."],"metadata":{"id":"PBNzusBwHKS0"}},{"cell_type":"code","source":["opt = tf.keras.optimizers.Lion()\n","\n","# Compile the model\n","model_1.compile(optimizer= opt,\n","              loss= dice_coef_loss,\n","              metrics=['accuracy', dice_coef_multilabel] )"],"metadata":{"id":"u97VknmM7K6N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' Model training '''\n","EPOCHS = 40\n","BATCH_SIZE = 32\n","\n","records = model_1.fit(x_train, y_train,\n","                    batch_size = BATCH_SIZE,\n","                    epochs = EPOCHS,\n","                    verbose = 1,\n","                    callbacks=[early_stopping]\n","                    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwvC_cHR7bCn","executionInfo":{"status":"ok","timestamp":1694425292601,"user_tz":-120,"elapsed":1402920,"user":{"displayName":"Anthea Silvia Sasdelli","userId":"09097632666158276833"}},"outputId":"33caa498-cf50-4280-b3ec-45e78b50a5d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","19/19 [==============================] - 134s 7s/step - loss: 0.9018 - accuracy: 0.1003 - dice_coef_multilabel: 0.0579\n","Epoch 2/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.8755 - accuracy: 0.1287 - dice_coef_multilabel: 0.0654\n","Epoch 3/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.8521 - accuracy: 0.1544 - dice_coef_multilabel: 0.0738\n","Epoch 4/40\n","19/19 [==============================] - 124s 6s/step - loss: 0.8272 - accuracy: 0.1820 - dice_coef_multilabel: 0.0830\n","Epoch 5/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.8027 - accuracy: 0.2093 - dice_coef_multilabel: 0.0920\n","Epoch 6/40\n","19/19 [==============================] - 124s 7s/step - loss: 0.7755 - accuracy: 0.2392 - dice_coef_multilabel: 0.0992\n","Epoch 7/40\n","19/19 [==============================] - 125s 7s/step - loss: 0.7494 - accuracy: 0.2681 - dice_coef_multilabel: 0.1047\n","Epoch 8/40\n","19/19 [==============================] - 123s 6s/step - loss: 0.7264 - accuracy: 0.2938 - dice_coef_multilabel: 0.1082\n","Epoch 9/40\n","19/19 [==============================] - 123s 6s/step - loss: 0.7058 - accuracy: 0.3166 - dice_coef_multilabel: 0.1106\n","Epoch 10/40\n","19/19 [==============================] - 123s 7s/step - loss: 0.6862 - accuracy: 0.3384 - dice_coef_multilabel: 0.1117\n","Epoch 11/40\n","19/19 [==============================] - 123s 6s/step - loss: 0.6663 - accuracy: 0.3601 - dice_coef_multilabel: 0.1132\n","Epoch 12/40\n","19/19 [==============================] - 124s 6s/step - loss: 0.6467 - accuracy: 0.3813 - dice_coef_multilabel: 0.1134\n","Epoch 13/40\n","19/19 [==============================] - 127s 7s/step - loss: 0.6276 - accuracy: 0.4016 - dice_coef_multilabel: 0.1146\n","Epoch 14/40\n","19/19 [==============================] - 125s 7s/step - loss: 0.6089 - accuracy: 0.4215 - dice_coef_multilabel: 0.1167\n","Epoch 15/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.5930 - accuracy: 0.4379 - dice_coef_multilabel: 0.1186\n","Epoch 16/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.5792 - accuracy: 0.4518 - dice_coef_multilabel: 0.1211\n","Epoch 17/40\n","19/19 [==============================] - 124s 7s/step - loss: 0.5666 - accuracy: 0.4641 - dice_coef_multilabel: 0.1270\n","Epoch 18/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.5562 - accuracy: 0.4732 - dice_coef_multilabel: 0.1294\n","Epoch 19/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.5471 - accuracy: 0.4804 - dice_coef_multilabel: 0.1316\n","Epoch 20/40\n","19/19 [==============================] - 131s 7s/step - loss: 0.5391 - accuracy: 0.4858 - dice_coef_multilabel: 0.1340\n","Epoch 21/40\n","19/19 [==============================] - 124s 6s/step - loss: 0.5309 - accuracy: 0.4909 - dice_coef_multilabel: 0.1355\n","Epoch 22/40\n","19/19 [==============================] - 124s 6s/step - loss: 0.5230 - accuracy: 0.4957 - dice_coef_multilabel: 0.1410\n","Epoch 23/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.5156 - accuracy: 0.5000 - dice_coef_multilabel: 0.1425\n","Epoch 24/40\n","19/19 [==============================] - 124s 6s/step - loss: 0.5094 - accuracy: 0.5035 - dice_coef_multilabel: 0.1454\n","Epoch 25/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.5037 - accuracy: 0.5071 - dice_coef_multilabel: 0.1446\n","Epoch 26/40\n","19/19 [==============================] - 123s 6s/step - loss: 0.4962 - accuracy: 0.5136 - dice_coef_multilabel: 0.1456\n","Epoch 27/40\n","19/19 [==============================] - 122s 6s/step - loss: 0.4642 - accuracy: 0.5494 - dice_coef_multilabel: 0.1478\n","Epoch 28/40\n","19/19 [==============================] - 118s 6s/step - loss: 0.4149 - accuracy: 0.5984 - dice_coef_multilabel: 0.1560\n","Epoch 29/40\n","19/19 [==============================] - 119s 6s/step - loss: 0.3834 - accuracy: 0.6269 - dice_coef_multilabel: 0.1584\n","Epoch 30/40\n","19/19 [==============================] - 118s 6s/step - loss: 0.3699 - accuracy: 0.6391 - dice_coef_multilabel: 0.1609\n","Epoch 31/40\n","19/19 [==============================] - 119s 6s/step - loss: 0.3640 - accuracy: 0.6449 - dice_coef_multilabel: 0.1613\n","Epoch 32/40\n","19/19 [==============================] - 119s 6s/step - loss: 0.3592 - accuracy: 0.6495 - dice_coef_multilabel: 0.1645\n","Epoch 33/40\n","19/19 [==============================] - 118s 6s/step - loss: 0.3556 - accuracy: 0.6520 - dice_coef_multilabel: 0.1664\n","Epoch 34/40\n","19/19 [==============================] - 119s 6s/step - loss: 0.3524 - accuracy: 0.6543 - dice_coef_multilabel: 0.1678\n","Epoch 35/40\n","19/19 [==============================] - 119s 6s/step - loss: 0.3500 - accuracy: 0.6559 - dice_coef_multilabel: 0.1710\n","Epoch 36/40\n","19/19 [==============================] - 118s 6s/step - loss: 0.3487 - accuracy: 0.6567 - dice_coef_multilabel: 0.1681\n","Epoch 37/40\n","19/19 [==============================] - 118s 6s/step - loss: 0.3467 - accuracy: 0.6583 - dice_coef_multilabel: 0.1677\n","Epoch 38/40\n","19/19 [==============================] - 119s 6s/step - loss: 0.3449 - accuracy: 0.6596 - dice_coef_multilabel: 0.1704\n","Epoch 39/40\n","19/19 [==============================] - 119s 6s/step - loss: 0.3436 - accuracy: 0.6605 - dice_coef_multilabel: 0.1715\n","Epoch 40/40\n","19/19 [==============================] - 119s 6s/step - loss: 0.3425 - accuracy: 0.6614 - dice_coef_multilabel: 0.1714\n"]}]},{"cell_type":"markdown","source":["##Metric\n","The comparison metric for this project is the Dice Cofficient for multi-class segmentation."],"metadata":{"id":"eEeoWxAth2pJ"}},{"cell_type":"markdown","source":["The Dice coefficient is defined by twice the overlapping area of the two masks, over the sum of the area of the two masks.\n","\n","![](https://miro.medium.com/max/429/1*yUd5ckecHjWZf6hGrdlwzA.png)\n","\n","The implementation of the dice coefficient is similar to the implementation of the IoU, since both of them explicitely uses that a mask is between 0 and 1."],"metadata":{"id":"JC2oeMaqHgZu"}},{"cell_type":"code","source":["# The Dice coefficient functions\n","\n","def dice_coef(y_true, y_pred):\n","\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = np.sum(y_true_f * y_pred_f)\n","    smooth = 0.0001\n","    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n","\n","def dice_coef_multilabel(y_true, y_pred):\n","    dice = 0\n","    for index in range(7):\n","        dice += dice_coef(y_true[:, :, :, index], y_pred[:, :, :, index])\n","    return dice / 7"],"metadata":{"id":"Is9BMmQt8HMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Dice coefficient function that shows the Dice coefficients for each class\n","\n","def dice_coef_for_each_class(y, y_pred):\n","\n","    # Ensure both y_true and y_pred have the same data type\n","    y_pred = y_pred.astype('float32')\n","    y = y.astype('float32')\n","\n","    # Calculate the Dice coefficient\n","    num_classes = y.shape[-1]\n","    dice_scores = []\n","\n","    for class_idx in range(num_classes):\n","        dice = dice_coef(y[..., class_idx], y_pred[..., class_idx])\n","        dice_scores.append(dice)\n","\n","    return dice_scores"],"metadata":{"id":"mdgTEtd_SWML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Predict the masks of the test set\n","\n","y_pred = model_1.predict(x_test)\n","\n","dice = dice_coef_multilabel(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOCCrsDJFjKV","executionInfo":{"status":"ok","timestamp":1694425608317,"user_tz":-120,"elapsed":13138,"user":{"displayName":"Anthea Silvia Sasdelli","userId":"09097632666158276833"}},"outputId":"3abdca7b-591c-4e86-b4bc-24c19982baeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7/7 [==============================] - 11s 2s/step\n"]}]},{"cell_type":"code","source":["print(f\"The Dice coefficient for the test set is {dice}.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARZyXJuGFlTF","executionInfo":{"status":"ok","timestamp":1694425608318,"user_tz":-120,"elapsed":7,"user":{"displayName":"Anthea Silvia Sasdelli","userId":"09097632666158276833"}},"outputId":"84c311e4-3381-423f-d37e-0ed808d102ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The Dice coefficient for the test set is 0.6201927948012534.\n"]}]},{"cell_type":"code","source":["dice_scores = dice_coef_for_each_class(y_test, y_pred)\n","\n","for class_idx, dice_score in enumerate(dice_scores):\n","    print(f\"Dice coefficient for class {class_idx}: {dice_score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sr8WYpwJWrc","executionInfo":{"status":"ok","timestamp":1694425378186,"user_tz":-120,"elapsed":2266,"user":{"displayName":"Anthea Silvia Sasdelli","userId":"09097632666158276833"}},"outputId":"a11e6c98-c6b9-400a-aef7-22e21e4bfc8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dice coefficient for class 0: 0.05918501719395228\n","Dice coefficient for class 1: 0.8105888124631282\n","Dice coefficient for class 2: 0.0006290135519489467\n","Dice coefficient for class 3: 0.21253295096886082\n","Dice coefficient for class 4: 0.12392971032437809\n","Dice coefficient for class 5: 0.00034925769269899106\n","Dice coefficient for class 6: 0.001356923391973737\n"]}]},{"cell_type":"markdown","source":["Here a visualization of the test dataset with the predicted masks is presented."],"metadata":{"id":"jBDIJThBMnm_"}},{"cell_type":"code","source":["for i in range(y_pred.shape[3]):\n","  show(x_test[100], y_test[110][...,i], ('This is the image', 'This is its relative mask of the channel '+str(i)))\n","  show(x_test[100], y_pred[110][...,i], ('This is the image', 'This is its relative predicted mask of the channel '+str(i)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19U94LbZ5b7AnXzh1nFHZfcIN5nQrGAEu"},"id":"QbCx9r-wMvFt","executionInfo":{"status":"ok","timestamp":1694425660897,"user_tz":-120,"elapsed":9247,"user":{"displayName":"Anthea Silvia Sasdelli","userId":"09097632666158276833"}},"outputId":"86071756-93ee-4ade-b776-57af043486df"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["##Conclusions\n","The U-Net proved to be a good choice for implementing the multiclass semantic segmentation task.\n","\n","According to the metrics used, namely the Dice coefficient function, the system worked well but there is definitely room for improvement.\n","\n","A possible update could be to add **weights of the classes** to the network based on their prevalence in the dataset as they are very unbalanced and the metrics are certainly affected and lowered.\n","\n","This can also be seen in the Dice coefficient plot for each class, where some classes have a significantly lower value than others.\n","For example the class 1 has a way better results than the class 5.\n"],"metadata":{"id":"0sPBXF__KBNG"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}